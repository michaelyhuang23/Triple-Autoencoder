### Triple Autoencoder
Triple Autoencoder is a failed experiment to create more controllable training method for image classification than normal gradient descent. The idea is that there's a frontend encoder which takes in an image and produce some latent features. We want to maximize the usefulness of these features. So we want them to be informative while relevant. What that means is that it should be able to produced a generalized image of what is perceived. If a dog is inputed, it should be able to generate features which can be decoded into the general outline of a dog. We don't want it to produce the exact same image as in normal autoencoders because that forces the encoder to learn features irrelevant to classification (for example: it may focus on the background instead of the dog).

Therefore, we need some way to factor into the generality of the features produced. The most generous image of dog for a neural network is the image that activates the dog neuron the most. In other words, for features to be general, they should be able to be used to activate the dog neuron. So to evaluate the generality of the autoencoder, we can attach another encoder at the end which outputs classification score and do gradient descent on all 3 (thus triple autoencoder).

The interesting part is that this could be extended if we could have some kind of generality coefficient at our control. We can train each layer using this model with varying generality coefficient, thus controlling the level of features that layer learns. It could provide more controlled learning.

However, experimentation shows this is useless (the model trains very very slowly). It's far more direct and quick to directly enforce generality by asking the model to predict whether the image is a dog or not, since it will be forced to only capture features relevant to dogs.